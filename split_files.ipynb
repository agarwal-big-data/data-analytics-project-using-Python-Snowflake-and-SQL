{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 6990280, Lines per file: 699028\n",
      "✅ JSON file successfully split into smaller parts!\n"
     ]
    }
   ],
   "source": [
    "import json                 # JSON module (not used directly, but kept for clarity)\n",
    "import os                   # OS utilities for file paths and directories\n",
    "\n",
    "input_file = \"/Users/deepdata/Downloads/Yelp JSON/yelp_dataset/yelp_academic_dataset_review.json\"  \n",
    "# Absolute path to the large Yelp JSON file (one JSON object per line)\n",
    "\n",
    "output_prefix = \"split_file_\"  \n",
    "# Prefix used for naming output split files (e.g., split_file_1.json)\n",
    "\n",
    "num_files = 10  \n",
    "# Number of smaller files the large JSON file will be split into\n",
    "\n",
    "output_dir = \"/Users/deepdata/Downloads/yelp_splits\"  \n",
    "# Directory where the split files will be saved (must be writable)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)  \n",
    "# Create the output directory if it does not already exist\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf8\") as f:  \n",
    "    total_lines = sum(1 for _ in f)  \n",
    "    # Count total number of lines (each line is one JSON record)\n",
    "\n",
    "lines_per_file = total_lines // num_files  \n",
    "# Calculate how many lines should go into each split file\n",
    "\n",
    "print(f\"Total lines: {total_lines}, Lines per file: {lines_per_file}\")  \n",
    "# Display line count information for verification\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf8\") as f:  \n",
    "    # Re-open the input file to start reading from the beginning\n",
    "\n",
    "    for i in range(num_files):  \n",
    "        # Loop to create each split file\n",
    "\n",
    "        output_filename = os.path.join(\n",
    "            output_dir, f\"{output_prefix}{i+1}.json\"\n",
    "        )  \n",
    "        # Construct full output file path for the current split\n",
    "\n",
    "        with open(output_filename, \"w\", encoding=\"utf8\") as out_file:  \n",
    "            # Open the output file in write mode\n",
    "\n",
    "            for j in range(lines_per_file):  \n",
    "                # Write the calculated number of lines to this split file\n",
    "\n",
    "                line = f.readline()  \n",
    "                # Read one line from the input file\n",
    "\n",
    "                if not line:  \n",
    "                    break  \n",
    "                    # Stop writing if end of input file is reached\n",
    "\n",
    "                out_file.write(line)  \n",
    "                # Write the line to the current output file\n",
    "\n",
    "print(\"✅ JSON file successfully split into smaller parts!\")  \n",
    "# Final success message after splitting is complete\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

